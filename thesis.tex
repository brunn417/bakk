% Copyright (C) 2014-2020 by Thomas Auzinger <thomas@auzinger.name>

\documentclass[draft,final]{vutinfth} % Remove option 'final' to obtain debug information.

% Load packages to allow in- and output of non-ASCII characters.
\usepackage{lmodern}        % Use an extension of the original Computer Modern font to minimize the use of bitmapped letters.
\usepackage[T1]{fontenc}    % Determines font encoding of the output. Font packages have to be included before this line.
\usepackage[utf8]{inputenc} % Determines encoding of the input. All input files have to use UTF8 encoding.

% Extended LaTeX functionality is enables by including packages with \usepackage{...}.
\usepackage{csquotes}   % used for easy quotes
\usepackage{amsmath}    % Extended typesetting of mathematical expression.
\usepackage{amssymb}    % Provides a multitude of mathematical symbols.
\usepackage{mathtools}  % Further extensions of mathematical typesetting.
\usepackage{microtype}  % Small-scale typographic enhancements.
\usepackage[inline]{enumitem} % User control over the layout of lists (itemize, enumerate, description).
\usepackage{multirow}   % Allows table elements to span several rows.
\usepackage{booktabs}   % Improves the typesettings of tables.
\usepackage{subcaption} % Allows the use of subfigures and enables their referencing.
\usepackage[ruled,linesnumbered,algochapter]{algorithm2e} % Enables the writing of pseudo code.
\usepackage[usenames,dvipsnames,table]{xcolor} % Allows the definition and use of colors. This package has to be included before tikz.
\usepackage{nag}       % Issues warnings when best practices in writing LaTeX documents are violated.
\usepackage{todonotes} % Provides tooltip-like todo notes.
\usepackage{hyperref}  % Enables cross linking in the electronic document version. This package has to be included second to last.
\usepackage[acronym,toc]{glossaries} % Enables the generation of glossaries and lists fo acronyms. This package has to be included last.

\usepackage{listings}

% Definieren der Sprache GraphQL für lstlisting
\lstdefinelanguage{GraphQL}{
	keywords={query, mutation, subscription, true, false, null},
	keywordstyle=\color{blue}\bfseries,
	ndkeywords={type, String, Int, Boolean, ID},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{\#},
	morestring=[b]",
	morestring=[b]',
}

\lstset{
	language=GraphQL,
	showstringspaces=false,
	extendedchars=true,
	basicstyle=\ttfamily\small,
	showspaces=false,
	showtabs=false,
	frame=single,
	tabsize=2,
	breaklines=true,
	showstringspaces=false
}

\lstdefinelanguage{REST}{
	keywords={GET, POST, PUT, DELETE, PATCH, HEAD},
	keywordstyle=\color{blue}\bfseries,
	ndkeywords={Content-Type, Authorization, Accept, WWW-Authenticate, X-Custom-Header},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{\#},
	morestring=[b]",
	morestring=[b]',
}

\lstset{
	language=REST,
	showstringspaces=false,
	extendedchars=true,
	basicstyle=\ttfamily\small,
	showspaces=false,
	showtabs=false,
	frame=single,
	tabsize=2,
	breaklines=true,
	showstringspaces=false
}

\lstset{
	language=PHP, 
	basicstyle=\ttfamily, 
	keywordstyle=\color{blue}\bfseries, 
	commentstyle=\color{green}, 
	stringstyle=\color{red}
}


% Define convenience functions to use the author name and the thesis title in the PDF document properties.
\newcommand{\authorname}{Paul Brunner} % The author name without titles.
\newcommand{\thesistitle}{} % The title of the thesis. The English version should be used, if it exists.

% Set PDF document properties
\hypersetup{
    pdfpagelayout   = TwoPageRight,           % How the document is shown in PDF viewers (optional).
    linkbordercolor = {Melon},                % The color of the borders of boxes around crosslinks (optional).
    pdfauthor       = {\authorname},          % The author's name in the document properties (optional).
    pdftitle        = {\thesistitle},         % The document's title in the document properties (optional).
    pdfsubject      = {Subject},              % The document's subject in the document properties (optional).
    pdfkeywords     = {a, list, of, keywords} % The document's keywords in the document properties (optional).
}

\setpnumwidth{2.5em}        % Avoid overfull hboxes in the table of contents (see memoir manual).
\setsecnumdepth{subsection} % Enumerate subsections.

\nonzeroparskip             % Create space between paragraphs (optional).
\setlength{\parindent}{0pt} % Remove paragraph identation (optional).

\makeindex      % Use an optional index.
\makeglossaries % Use an optional glossary.
%\glstocfalse   % Remove the glossaries from the table of contents.

% Set persons with 4 arguments:
%  {title before name}{name}{title after name}{gender}
%  where both titles are optional (i.e. can be given as empty brackets {}).
\setauthor{}{\authorname}{}{}
\setauthorextra
\setadvisor{Dipl.-Ing.}{Thomas Artner}{}{male}

% For bachelor and master theses:
%\setfirstassistant{Pretitle}{Forename Surname}{Posttitle}{male}
%\setsecondassistant{Pretitle}{Forename Surname}{Posttitle}{male}
%\setthirdassistant{Pretitle}{Forename Surname}{Posttitle}{male}

% For dissertations:
\setfirstreviewer{Pretitle}{Forename Surname}{Posttitle}{male}
\setsecondreviewer{Pretitle}{Forename Surname}{Posttitle}{male}

% For dissertations at the PhD School and optionally for dissertations:
\setsecondadvisor{Pretitle}{Forename Surname}{Posttitle}{male} % Comment to remove.

% Required data.
\setregnumber{11919163}
\setdate{01}{06}{2024} % Set date with 3 arguments: {day}{month}{year}.
\settitle{\thesistitle}{Die Evaluierung und Implementierung einer Web-API} % Sets English and German version of the title (both can be English or German). If your title contains commas, enclose it with additional curvy brackets (i.e., {{your title}}) or define it as a macro as done with \thesistitle.
\setsubtitle{Optional Subtitle of the Thesis}{Technologieevaluierung und Implementierung einer Web-
		Schnittstelle für Gebäudezertifizierungsdaten:
		Eine Fallstudie bei der Pulswerk GmbH.} % Sets English and German version of the subtitle (both can be English or German).

% Select the thesis type: bachelor / master / doctor / phd-school.
% Bachelor:
\setthesis{bachelor}
%
% Master:
%\setthesis{master}
%\setmasterdegree{dipl.} % dipl. / rer.nat. / rer.soc.oec. / master
%
% Doctor:
%\setthesis{doctor}
%\setdoctordegree{rer.soc.oec.}% rer.nat. / techn. / rer.soc.oec.
%
% Doctor at the PhD School
%\setthesis{phd-school} % Deactivate non-English title pages (see below)

% For bachelor and master:
\setcurriculum{Media Informatics and Visual Computing}{Software \& Information Engineering} % Sets the English and German name of the curriculum.

% For dissertations at the PhD School:
\setfirstreviewerdata{Affiliation, Country}
\setsecondreviewerdata{Affiliation, Country}


\begin{document}

\frontmatter % Switches to roman numbering.
% The structure of the thesis has to conform to the guidelines at
%  https://informatics.tuwien.ac.at/study-services

%\addtitlepage{naustrian} % German title page (not for dissertations at the PhD School).
% \addtitlepage{english} % English title page.
\addinsotitlepage{naustrian}
\addstatementpage

\begin{danksagung*}
\todo{Ihr Text hier.}
danke mutti
\end{danksagung*}

\begin{acknowledgements*}
\todo{Enter your text here.}
wtf ist das
\end{acknowledgements*}

\begin{kurzfassung}
\todo{Ihr Text hier.}
Dieses Template dient als Vorlage für die Erstellung einer Diplomarbeit am INSO. Individuelle Erweiterungen, Strukturanpassungen und Layout-Veränderungen können und sollen selbstverständlich nach persönlichem Ermessen und in Rücksprache mit Ihrem Betreuer vorgenommen werden. 

Diplomarbeiten aus Informatik können in deutscher oder englischer Sprache verfasst werden, Arbeiten aus Business Informatics müssen auf Englisch geschrieben werden.

Die Kurzfassung ist der Teil der Arbeit, der wohl am häufigsten gelesen wird – so wird sie beispielsweise im Epilog-Band der Fakultät publiziert und einem breiten Publikum verfügbar gemacht. Empfohlen wird, die Kurzfassung erst nach Finalisierung der gesamten Arbeit zu schreiben.

Aufbau: In der Kurzfassung werden auf einer 3/4 bis maximal einer Seite die Kernaussagen der Diplomarbeit zusammengefasst. Dabei sollte zunächst die Motivation/ der Kontext der vorliegenden Arbeit dargestellt werden, und dann kurz die Frage-/ Problemstellung erläutert werden, max. 1 Absatz! Im nächsten Absatz auf die Methode/ Verfahrensweise/ das konkrete Fallbeispiel eingehen, mit deren Hilfe die Ergebnisse erzielt wurden. Im Zentrum der Kurzfassung stehen die zentralen eigenen Ergebnisse der Arbeit, die den Wert der vorliegenden wissenschaftlichen Arbeit ausmachen. Hier auch, wenn vorhanden, eigene Publikationen erwähnen.

Wichtig: Verständlichkeit! Abkürzungen immer zuerst ausschreiben, in Klammer die Erklärung: Im Rahmen der vorliegenden Arbeit werden Non Governmental-Organisationen (NGOs) behandelt, \ldots

Bei theoretischen Diplomarbeiten, z.B. Literaturüberblick und Grundlagen zu einem größeren Themenblock, sollte in der Kurzfassung deutlich der Bedarf an einer solchen Übersicht und der Nutzen für die akademische Gemeinschaft aufgezeigt werden.


\textbf{Keywords:} \emph{5 – max. 8 Keywords zur Arbeit eingeben}
\end{kurzfassung}

\begin{abstract}
\todo{Enter your text here.}
Hier werden auf einer halben bis maximal einer Seite die Kernaussagen der Diplomarbeit in Englisch zusammengefasst ( = Übersetzung der Kurzfassung, am besten von einem \enquote{Native Speaker} Korrektur lesen lassen). Englischer Abstract ist auch bei auf Deutsch geschriebenen Arbeiten verpflichtend von der Fakultät vorgesehen.


\textbf{Keywords:} \emph{Übersetzung der deutschen Keywords}
\end{abstract}

% Select the language of the thesis, e.g., english or naustrian.
\selectlanguage{naustrian}

% Add a table of contents (toc).
\tableofcontents % Starred version, i.e., \tableofcontents*, removes the self-entry.

% Switch to arabic numbering and start the enumeration of chapters in the table of content.
\mainmatter


\chapter{EINLEITUNG}

\section{Hintergrund und Motivation}

Die Pulswerk GmbH ist seit mehr als 2 Jahren mein Arbeitgeber.
Ihr Tätigkeitsbereich ist sehr umfassend, aber einer der Kernbereiche ist die Bereitstellung von Web-Applikationen zur Zertifizierung von Gebäudedaten.
Für verschiedene Zertifikate und Kunden gibt es unterschiedliche Plattformen und Kriteriensets, jedoch ist eine generische Grundstruktur die Basis. 
Mein derzeitiger Tätigkeitsbereich ist die Qualitätssicherung und Unterstützung bei der Weiterentwicklung dieser Plattformen.
Diese Gebäude-spezifischen Daten sind auf dem Webserver der Pulswerk GmbH gespeichert und nur über diese Formulare und bestimmten Webseiten zugänglich.
Damit ein strukturierter und übersichtlicher Zugang zu diesen Daten ermöglicht wird, soll eine Web-Schnittstelle in Form eines Application Programming Interface (API) implementiert werden.

Im Zuge dieser Bachelorarbeit für Informatik, die zum Abschluss des Bachelorstudiums Software \& Information 033 534 Engineering an der Technische Universität Wien Voraussetzung ist, werde ich diese Problemstellung behandeln und zu einer Lösung beitragen.
 
 
\section{Zielsetzung der Arbeit}

Da es in der Zukunft viele unterschiedliche Benutzergruppen dieser Schnittstelle geben soll, wird eine generische, aber auf die Anforderungen abgestimmte, Implementierung erwartet. 
Um dies zu ermöglichen, muss im Vorfeld der Implementierung eine genaue Evaluierung der verschiedenen Technologien und Ansprüche durchgeführt werden.
 
Das Ziel dieser Arbeit ist es, den derzeitigen Stand der Technik in Bezug auf Web-Schnittstellen zu recherchieren und auf dem erlangten Wissen aufbauend eine API entwerfen.
Diese soll nicht nur den Ansprüchen der Stakeholder gerecht werden, sondern auch technische nicht funktionale Anforderungen erfüllen.
Dabei sind Aspekte wie Sicherheit, Antwortzeit, Benutzerfreundlichkeit und Skalierbarkeit grundlegende Kriterien, aber auch Parameter wie Over- und Underfetching
\footnote{
	Underfetching tritt auf, wenn eine Schnittstellenabfrage nicht alle erwünschten Daten in der Antwort enthält wohingegen beim Overfetching mehr als das Angeforderte retourniert wird.
} 
sind von Bedeutung und werden bei der Anforderungsanalyse berücksichtigt. 

Mittels Continuous Deployment soll eine nahtlose Integration in die bestehende Systemlandschaft der Pulswerk GmbH ermöglicht werden. 
Dies gewährleistet, dass die Web-Schnittstelle nicht nur den momentanen Anforderungen gerecht wird, sondern auch entsprechend flexibel ist, um sich an zukünftige Entwicklungen anzupassen.


\section{Struktur der Arbeit}

Zum Beginn der Arbeit werden mögliche Anwendungsfälle simuliert und in Zusammenarbeit mit den Stakeholder eine Anforderungsanalyse durchgeführt. 
Dabei werden die funktionalen und nicht-funktionalen Anforderungen untersucht und festgelegt.
Die daraus resultierenden Leistungsanforderungen liefern das Grundkonzept für die Schnittstelle. 

Im nächsten Schritt wird eine umfassende Recherche des aktuellen Stands der Technik und dazugehörenden Literatur durchgeführt. 
Hier liegt der Fokus auf der Auswahl welches Entwurfsmuster für diesen Anwendungsfall herangezogen werden soll und mithilfe welcher Technologien die Implementierung umzusetzen ist. 

Nach der Technologieevaluierung wird eine prototypische Implementierung gemacht. 
Dabei werden relevante Technologien und Frameworks entsprechend den Projektanforderungen ausgewählt. 
Dieser Prototyp dient als Grundlage für die iterative Verbesserung und Entwicklung einer vollständigen Web-Schnittstelle.

Nach der prototypischen Implementierung wird abschließend eine Validierung und Einschätzung der entwickelten Web-Schnittstelle durch Experteninterviews durchgeführt. 
Ziel ist es, Fachwissen und Erfahrung externer und interner Experten zu nutzen, um die entwickelte Lösung kritisch zu bewerten und mögliche Schwachstellen oder Optimierungspotenziale aufzudecken.










\chapter{GRUNDLAGEN}

Im Grundlagenkapitel wird zunächst das Beratungsunternehmen Pulswerk GmbH vorgestellt, gefolgt von einer Betrachtung der wesentlichen Web-Anwendungen. Anschließend wird die Notwendigkeit einer Web-API für Datenzugriff erläutert. 
Im weiteren Verlauf werden theoretische Konzepte und Designprinzipien von Web-Schnittstellen behandelt, die für die Erstellung benutzerfreundlicher und zukunftsfähiger APIs erforderlich sind.
Abschließend werden die Anforderungen an die Schnittstelle definiert, die aus einer detaillierten Analyse resultieren. 


\section{Beschreibung des Unternehmens und der Webapplikationen}

Die Pulswerk GmbH, ein Tochterunternehmen des Österreichischen Ökologie-Instituts, hat sich seit ihrer Gründung 1985 als ein Akteur im Bereich der ökologischen und nachhaltigen Entwicklung etabliert. 
Das Unternehmen tritt in einer breiten Palette von Sektoren als Initiator und Mitgestalter für zukunftsfähige Projekte auf und engagiert sich in diversen Netzwerken für die Planung und Realisierung nachhaltiger Initiativen.

Ein spezifischer Fokus der Pulswerk GmbH liegt auf dem Baugewerbe, insbesondere in Bezug auf Herausforderungen des Klimaschutzes. 
Sie bietet einige Webapplikationen an, die es ermöglichen, Gebäude nach verschiedenen Richtlinien wie klimaaktiv
\footnote{
	klimaaktiv ist ein österreichisches Programm zur Förderung klimafreundlichen Bauens, unterstützt durch das Bundesministerium für Klimaschutz. 
	Es bietet unter Anderem Zertifizierungen für energieeffiziente und nachhaltige Gebäude.
} 
oder EU-Taxonomie
\footnote{
	Die EU-Taxonomie ist ein EU-Klassifikationssystem, das festlegt, welche Investitionen als ökologisch nachhaltig
	gelten, um grüne Investitionen zu unterstützen und den Klimaschutz voranzutreiben.
	Die EU-Taxonomie bezieht sich auf alle Wirtschaftssektoren, wobei sich die Pulswerk GmbH mit dem Bausektor befasst. 
} 
einfach und ohne bürokratischen Aufwand zu zertifizieren. 

Diese Kataloge, die als umfangreiche Formulare mit diversen Eingabeoptionen wie Textfeldern, Checkboxen, Radio-Buttons und Upload-Funktionen konzipiert sind, erlauben Nutzern, Daten einzutragen und abhängig von Plattform und spezifischem Kriterienkatalog Punkte zu erhalten.
Innerhalb der verschiedenen Plattformen kommen unterschiedliche Kriterienkataloge zum Einsatz, die sich nicht nur zwischen den einzelnen Webapplikationen unterscheiden, sondern auch innerhalb einer Plattform abhängig von der Version, dem Gebäudetyp und anderen Faktoren variieren können. 
Zusätzlich ist es möglich, sofern es konfiguriert wurde, Projekte auch zwischen verschiedenen Kriterienkataloge zu verschieben, und die übereinstimmenden Felder werden übernommen. 
Somit können Projekte gleichzeitig für mehrere Zertifizierungen deklariert und eingereicht werden.

Sobald ein Projekt alle Mindestanforderungen erfüllt und die Eingaben komplettiert sind, kann es zur Plausibilitätsprüfung eingereicht werden. 
Diese Prüfung wird von internen oder externen Auditoren vorgenommen und kann sich über mehrere Durchläufe erstrecken. 
Nach erfolgreichem Abschluss der Überprüfung besteht die Option, das zertifizierte Gebäude auf verschiedenen Webseiten visuell ansprechend aufbereitet zu präsentieren und damit für die Öffentlichkeit zugänglich zu machen.


\section{Erfordernis einer API für den internen und externen Datenzugriff}

In der aktuellen Dateninfrastruktur der Plattformen befinden sich über 10.000 Gebäudedatensätze, die entweder noch bearbeitet oder bereits finalisiert sind. 
Die dezentrale Verteilung dieser Datensätze schränkt jedoch die Möglichkeit eines kontrollierten Zugriffs ein. 
Daraus ergibt sich die Notwendigkeit einer Schnittstelle, die in der Lage ist, effizient durch diese umfangreichen Datenbestände zu navigieren und die geforderten Informationen abzurufen. 
Diese Schnittstelle ermöglicht somit einen systematischen und strukturierten Zugang zu den in Datenbanken auf dem Server gespeicherten Datensätzen und trägt damit zur Optimierung der Datenverwaltung und Datennutzung bei.

Von solch einer Schnittstelle profitieren sowohl interne Teams als auch externe Kunden. 
Für die internen Operationen der Pulswerk GmbH ermöglicht die Schnittstelle eine vertiefte Analyse und Evaluation der durchgeführten Arbeiten, was zu einer verbesserten Effizienz und Effektivität der internen Prozesse beitragen kann. 
Externe Kunden erhalten durch die API einen detaillierten Einblick in ihre individuellen Beiträge und den jeweiligen Fortschritt in Bezug auf Klimaschutzmaßnahmen. 
Zusätzlich unterstützt die Integration der API eine nahtlose Kommunikation mit bestehenden Abrechnungssystemen, wie z.B. SAP
\footnote{
	Systems, Applications \& Products in Data Processing ist ein weltweit führendes Unternehmen im Bereich Unternehmenssoftware. 
	Diese Software unterstützt Firmen bei der Verwaltung und Optimierung ihrer Geschäftsprozesse.
}
, was eine Vereinfachung der Geschäfts- und Abrechnungsprozesse zur Folge hat.
Den Kunden wird über diese Plattform Zugang gewährt, wobei der Zugriff durch entsprechende Berechtigungen reguliert wird. 
Die Entwicklung einer generischen API, die diesen Anforderungen gerecht wird, sowie die Erstellung einer nachvollziehbaren Dokumentation bildet die essentielle Basis, um Benutzerfreundlichkeit des Systems sicherzustellen.


\section{Theoretische Konzepte von Web-Schnittstellen}

APIs sind essentielle Mechanismen, die Interaktionen zwischen zwei Softwarekomponenten ermöglichen. 
Beide Seiten verwenden dafür bestimmte Schnittstellenspezifikationen und Protokolle, um einen nahtlosen Datenaustausch zu gewährleisten, oder im Fehlerfall aussagekräftige Fehlermeldungen bereitzustellen.
Es existiert eine Vielzahl an Architekturen solcher Schnittstellen, die je nach Anwendungsfall eingesetzt werden.
Im Grundsatz sendet eine Client-Applikation eine Anfrage, die über ein Netzwerk an den Server gerichtet wird. 
Dieser interpretiert die Anfrage gemäß der API-Konventionen, verarbeitet diese, und antwortet dem Client mit den angefragten Daten.

Web-Schnittstellen repräsentieren eine spezialisierte Kategorie von APIs, die spezifisch für eine Kommunikation zwischen Web-Clients –- üblicherweise Web-Browsern –- und Web-Servern ausgelegt sind. 
Hierbei wird der Datenaustausch über das Hypertext Transfer Protocol (HTTP) oder dessen sichere Variante, HTTPS, abgewickelt, wobei eine große Bandbreite an Datenformaten wie HTML, XML oder JSON zum Einsatz kommen kann.


\section{Designprinzipien von Web-Schnittstellen}

Die Designs von APIs unterliegen einer Vielzahl von Ansätzen, deren übergreifendes Ziel es ist, eine robuste und intuitiv bedienbare Schnittstelle zu entwickeln. 
Im Zentrum steht der Entwurf einer API, die nicht nur in ihrer Lebensdauer beständig, sondern auch wartungsarm ist. 
Eine effektive API zeichnet sich durch ihre Benutzerfreundlichkeit aus und bedarf keiner umfangreichen Dokumentation, da sie weitgehend selbsterklärend sein soll \cite{Bloch:2006:How2DesignGoodAPI}.

Im Vorfeld der Entwicklung einer solchen Schnittstelle ist eine umfassende Anforderungsanalyse essenziell, um eine adäquate Erfüllung der spezifischen Ansprüche zu gewährleisten. 
Mit der Weiterentwicklung der Anwendungsfälle muss auch die API in ihrer Funktionalität flexibel und adaptiv gestaltet sein, um zukünftigen Anforderungen gerecht zu werden. 
Dies bedingt, dass die Weiterentwicklung der API stets unter Berücksichtigung dieser dynamischen Entwicklung erfolgt. \cite{Bloch:2006:How2DesignGoodAPI}

Des Weiteren spielen aussagekräftige Beispiele für die Nutzung der API eine grundlegende Rolle, um deren Leistungsfähigkeit und Anwendbarkeit zu veranschaulichen. 
Die Klarheit in der Namensgebung ist ein weiterer kritischer Faktor, der die Zugänglichkeit und Verständlichkeit der API maßgeblich beeinflusst. 
Darüber hinaus ist es vorteilhaft, wenn alle Anfragen im String-Format verarbeitet werden können und die API konsistente sowie typgerechte Rückgabeformate liefert, um die Datenverarbeitung und Datenintegration zu vereinfachen. \cite{Bloch:2006:How2DesignGoodAPI}









\chapter{Methode}

Die primäre Zielsetzung dieser Arbeit besteht darin, den aktuellen Stand der Technik zu evaluieren und eine den spezifischen Anforderungen gerecht werdende Web-Schnittstelle zu implementieren. 
Zur Realisierung dieser Ziele basiert die angewandte Methodik auf einer Kombination von theoretischen, praktischen und empirischen Untersuchungsansätzen.

Der erste Schritt in dieser Arbeit umfasst eine detaillierte Anforderungsanalyse, die in enger Kooperation mit den Stakeholdern durchgeführt wird. 
Hierbei werden die funktionalen und nicht-funktionalen Anforderungen der Web-Schnittstelle sorgfältig untersucht und festgelegt. 
Zur präzisen Abbildung und detaillierten Spezifikation der Anforderungen wird die Unified Modeling Language (UML) verwendet. 
Dieses Modellierungswerkzeug ermöglicht es, komplexe Systemanforderungen übersichtlich und nachvollziehbar darzustellen.
Nach Abschluss der Anforderungsanalyse erfolgt eine umfassende Literaturrecherche sowie die Analyse bestehender Forschungsarbeiten und Technologien im Bereich der Web-Schnittstellen.
Diese Phase dient dazu, einen fundierten Überblick über den derzeitigen Entwicklungsstand und bestehende Lösungsansätze zu gewinnen.

Nachdem alle Anforderungen an die Schnittstelle und der Stand der Technik analysiert ist, erfolgt die Auswahl einer geeigneten Technologie. 
Auf der Basis dieser Entscheidung wird der systematische Entwurf der Web-Schnittstelle entwickelt. 
Diese Phase beinhaltet die Konzeption der Architektur und der funktionalen Eigenschaften der Schnittstelle, die sicherstellen soll, dass alle Nutzeranforderungen effektiv erfüllt werden.
Die darauf folgende Phase der prototypischen Implementierung nutzt ein auf Hypertext Preprocessor (PHP) basierendes Web-Framework, das speziell auf die erarbeiteten Anforderungen abgestimmt ist. 
Während dieser Entwicklungsphase wird ein funktionierender Prototyp der Schnittstelle erstellt, der als Basis für weitere Iterationen und Feinabstimmungen dient.

Abschließend wird die entwickelte Web-Schnittstelle einer eingehenden Evaluierung durch Experteninterviews unterzogen. 
Die Feedbacks und Einschätzungen der Experten werden systematisch erfasst und ausgewertet, um die Funktionalität und Qualität der implementierten Schnittstelle zu beurteilen. 
Die Ergebnisse dieser Evaluierung fließen direkt in die abschließende Überarbeitung und Optimierung der Web-Schnittstelle ein, um eine hohe Benutzerfreundlichkeit und technische Leistungsfähigkeit sicherzustellen.










\chapter{Anforderungsanalyse}

In diesem Kapitel erfolgt zunächst eine eingehende Anforderungsanalyse, um eine solide Basis für das Design der Web-Schnittstelle zu schaffen. 
Mithilfe von Use Cases werden die funktionalen Anforderungen präzise definiert und erläutert. 
Die nicht-funktionalen Anforderungen werden in Zusammenarbeit mit der Expertise unserer internen Teammitglieder festgelegt, um eine umfassende Spezifikation der Systemeigenschaften zu gewährleisten.


\section{Use Cases}
\label{sec:useCases}

Die Use Cases stellen zentrale Anwendungsszenarien der zu entwickelnden Schnittstelle dar und liefern wichtige Einblicke in die praktische Nutzung des Systems. 
Sie dienen als Grundlage, um die Interaktionen der Nutzer:innen mit der Schnittstelle zu verstehen und entsprechend zu gestalten. 
Diese Szenarien sind entscheidend für die Identifizierung kritischer Funktionen und der daraus resultierenden Anforderungen an das System.


\subsection{Benutzerdaten}

Ein zentraler Endpunkt der Schnittstelle ist das Abrufen von Benutzerdaten und deren Projekte. 
Jede:r Benutzer:in einer Gebäudedeklarations-Plattform wird durch eine eindeutige ID identifiziert. 
Um diese IDs abzurufen, soll die Schnittstelle die Möglichkeit bieten, mittels eines case-insensitiven 
\footnote{
	Case-insensitve ist das Ignorieren von Klein- und Großbuchstaben in Datenbankabfragen.
}
Substrings
\footnote{
	Strings ist ein Datentyp der jede Art von Zeichenreihen beschreibt und Substrings sind echte Teilmengen dieser Strings.
}
des Namens eine Liste aller Benutzer:innen zu generieren, die diesen Namen enthalten. Neben jedem Namen wird entsprechend die zugehörige ID angezeigt.
Basierend auf der ermittelten ID soll ein weiterer Endpunkt eingerichtet werden, der alle Projekte retourniert, die dem:der Benutzer:in mit dieser ID zugeordnet sind.


\subsection{Gebäudedaten}

Der Fokus dieser Arbeit liegt auf der Analyse von Gebäudedaten, wofür eine Vielzahl spezifischer Endpunkte erforderlich ist. 
Diese dienen dazu, detaillierte und gut strukturierte Auswertungen zu ermöglichen und eine solide Basis für die Entwicklung zukünftiger Dashboards zu bieten. 
Ein wesentliches Problem besteht darin, dass auf verschiedenen Plattformen in allen Kriteriensets die Felder durch nicht-selbstbeschreibende Identifikatoren gekennzeichnet sind. 
Um einen umfassenden Überblick über diese Felder zu gewinnen, ist ein spezieller Endpunkt notwendig, der für jedes Kriterienset die Feldnamen, deren Beschreibungen sowie den Feldtyp zurückliefert. 
Zusätzlich ermöglicht ein weiterer Endpunkt, mithilfe des eindeutigen Feldnamens als Parameter, das Abrufen aller Werte eines spezifischen Feldes über alle Projekte hinweg.
Jedes Projekt ist durch eine eindeutige ID gekennzeichnet, die genutzt werden kann, um alle Projektdaten abzurufen.


\subsection{Übersicht der Endpunkte}

Hier findet sich eine zusammenfassende Auflistung der zuvor diskutierten Endpunkte.
Für all diese Endpunkte gibt es eine strukturierte Authentifizerungs-Strategie. 
So werden User:innen nur mit gewissen Rechten auf gewisse Endpunkte zugreifen können, um einen Missbrauch der Daten zu vermeiden.

\begin{lstlisting}[
		caption={Benutzerspezifische Datenabfragen}
	]
	function getUsersByNameSubstring($name) {
		return array($userIds, $names);
	}
	
	function getAllProjectsFromUserById($id) {
		return array($projectName, $projectId);
	}
\end{lstlisting}

\begin{lstlisting}[
		caption={Gebäudespezifische Datenabfragen}
	]
	function getProjectById($id) {
		return $Project;
	}
	
	function getAllFieldIdentifiersOfKriteriensetById($id) {
		return array($fieldIdentifier, $fieldType, $fieldDescription);
	}
	
	function getValuesOfFieldOverAllProjects($fieldname) {
		return array($projectId, $value);
	}
	
\end{lstlisting}

%	function getAllProjectsWithGivenValue($fieldName, $value) {
%		return array(%projectId, %projectName)	
%	}

\todo{UML API Diagramm mit Swagger wenn api fertig}


\section{Funktionale Anforderungen}

Aus den oben beschriebenen \nameref{sec:useCases} ergeben sich somit die funktionalen Anforderungen an die Schnittstelle:

\begin{enumerate}
	
	\item \textbf{Benutzerdaten abrufen:}
	
		 Entwicklung eines Endpunkts zur Ermittlung der eindeutigen ID mittels eines case-insensitiven Substrings des Namens.
	
	\item \textbf{Projektdaten abrufen:}
	
		Bereitstellung eines Endpunkts, der anhand einer eindeutigen Benutzer-ID alle zugehörigen Projekte retourniert.

	\item \textbf{Gebäudedaten analysieren:}
	
		Implementierung spezifischer Endpunkte zur Unterstützung detaillierter Auswertungen von Gebäudedaten und die Entwicklung von Endpunkten zur Rückgabe von Informationen zu allen Kriteriensets, einschließlich Feldnamen, Feldbeschreibungen und Feldtypen.

	\item \textbf{Datenintegration für Dashboards:}
	
		Schaffung einer Datenbasis, die die Entwicklung von Dashboards unterstützt und detaillierte, strukturierte Auswertungen ermöglicht.
	
	\item \textbf{Feldwertabfragen über alle Projekte:}
	
		Einrichtung eines Endpunkts, der mithilfe eines eindeutigen Feldnamens als Parameter, alle Werte eines spezifischen Feldes über alle Projekte hinweg zurückgibt.
	
	\item \textbf{Einzelprojektabfragen:}
	
		Bereitstellung eines Endpunkts zur Abfrage von Projektdaten anhand einer eindeutigen Projekt-ID.
	
	\item \textbf{Authentifizierung:}
	
		Ein Anmeldetool zum erstellen einen Authentifizierungstoken, der über die HTTP-Header mitgeschickt wird. 
		So wird ein kontrollierter Zugriff zu den Daten ermöglicht.
	
\end{enumerate}


\section{Nicht-funktionale Anforderungen}

Ausgehend von der Konferenz OOPSLA '06 --- einer renommierten Veranstaltung im Bereich der objektorientierten Programmiersysteme, Sprachen und Anwendungen --- und der Anforderungsanalyse in Zusammenarbeit mit Kolleg:innen ergeben sich folgende nicht-funktionale Anforderungen \cite{Bloch:2006:How2DesignGoodAPI}.

\begin{enumerate}
	
	\item \textbf{Bedienbarkeit:}
	
	Die Schnittstelle soll intuitiv nutzbar sein, wobei die Endpunkte selbsterklärende Bezeichnungen tragen und eine klare Struktur aufweisen. 
	Dies umfasst logisch benannte Funktionen und Pfade, die zu einer mühelosen Bedienung beitragen.
	
	\item \textbf{Fehlerbehandlung:}
 
	Essentiell für ein gutes System ist auch eine konsistente und transparente Fehlerbehandlung, die den Anwender:innen schnelle und verständliche Rückmeldungen bietet.
	
	\item \textbf{Dokumentation:}
	
	Die Dokumentation der Schnittstelle ist gemäß dem Stil der OpenAPI-Spezifikation anzufertigen. Sie wird detaillierte Beschreibungen der Serverendpunkte, der Funktionen sowie der Datentypen enthalten. 
	Um den Nutzer:innen eine praxisnahe Orientierung zu bieten, sollen zudem anschauliche Anwendungsbeispiele integriert werden.
	
	\item \textbf{Performance}
	Während extreme Geschwindigkeit nicht das primäre Ziel ist, soll die Performance der Schnittstelle dennoch effizient sein, um Verzögerungen zu vermeiden und eine angemessene Antwortzeit zu gewährleisten. 
	Ein Gleichgewicht zwischen schneller Ausführung und Ressourcenoptimierung ist für eine zufriedenstellende Benutzererfahrung erforderlich.
	
	\item \textbf{Tests}
	Regelmäßige Tests sind für die Aufrechterhaltung der Schnittstellenqualität unerlässlich. 
	Die Endpunkte sollen daher kontinuierlich in einem CI/CD-Prozess getestet werden, um Stabilität und Zuverlässigkeit sicherzustellen und eine durchgehende Funktionalität zu garantieren.
	
\end{enumerate}









\chapter{State of the Art Analyse}
\label{chap:stateOfTheArt}

In den letzten Jahren hat der Bereich der Web-Schnittstellen, gesteuert durch die Zunahme an Webanwendungen, eine dynamische Entwicklung erfahren. Diese Entwicklung wird durch eine Vielzahl von wissenschaftlichen Arbeiten unterstrichen, die sich mit den verschiedenen Aspekten und Herausforderungen von Web-APIs auseinandersetzen. 
Um einen fundierten Überblick über den aktuellen Wissensstand im Bereich der Web-APIs zu erhalten, ist eine Analyse bestehender Forschungsarbeiten notwendig.  
Im weiteren Verlauf dieser Arbeit liegt der Fokus auf der Untersuchung spezifischerer Themengebiete, um eine Technologieevaluierung durchführen zu können. 
Dabei werden insbesondere die Vor- und Nachteile verschiedener Technologien im Kontext der Entwicklung und Implementierung von Web-Schnittstellen beleuchtet.


\section{Web-APIs}

Die Nutzung von Web-Schnittstellen birgt Herausforderungen, insbesondere aufgrund des Fehlens einheitlicher Standards \cite{Alrashed:2021:StandardizingAPIs}. 
Obwohl viele Webseiten Dritten den Zugang zu ihren Daten über Web-APIs gewähren, stellt die manuelle Erstellung von URLs -- einschließlich der Festlegung von Endpunkten, Parametern, Authentifizierungsprozessen und der Handhabung von Seitenumbrüchen -- eine erhebliche Hürde dar 
\cite{Alrashed:2021:StandardizingAPIs, Maleshkova:2010:InvestigationWebAPIs}. 
Diese Prozesse erfordern ein tiefgehendes Verständnis und sind mit einem beträchtlichen Zeitaufwand verbunden \cite{Alrashed:2021:StandardizingAPIs}. 
Zudem verfügt eine große Anzahl dieser Web-APIs über individuelle Datenmodelle, die, obwohl sie häufig ähnliche Arten von Informationen verwalten, unterschiedliche Methoden und Eigenschaften auf ihre eigene Weise bereitstellen \cite{Alrashed:2021:StandardizingAPIs}.
Um sich Zugang zu diesen Systemen zu ermöglichen, ist es notwendig, sich mit diesen im Voraus vertraut zu machen. 
Jedoch wird dies durch die Vielfalt und oft inkonsistente Art der Dokumentation zusätzlich erschwert \cite{Maleshkova:2010:InvestigationWebAPIs}.

Eine umfangreiche empirische Studie von S. Serbout,  F. D. Lauro und C. Pautasso, die auf der IEEE International Conference on Software Architecture Workshops 2022 vorgestellt wurde, untersucht die Größe und Struktur von Web-API-Spezifikationen, die aus Open-Source-Repositories extrahiert wurden. Diese Web-APIs umfassen neben der Dokumentation der bereitgestellten Operationen auch Schemadefinitionen für den Datenaustausch bei API-Anfragen und API-Antworten. 
Durch die Analyse von 42.194 gültigen OpenApi Specifications (OAS)
\footnote{
	OAS ist ein Standard zur Beschreibung von RESTful APIs, der die Generierung von Dokumentation ermöglicht.
}
, die zwischen 2014 und 2021 veröffentlicht wurden und von bekannten Dienstanbietern wie Google und Amazon stammen, zeigt die Studie verschiedene Metriken auf. 
Der Mittelwert über alle diese Schnittstellen ist 3,98 Pfade zu 5,23 Operationen. 
Außerdem wurde eine Korrelation zwischen der Größe der API und Art des Designkonzeptes entdeckt. 
So sind kleine Schnittstellen meißt nur Read-Only und in Remote Procedure Call (RPC) Stil implementiert. 
Wohingegen Schnittstellen mit drei oder mehr Pfade in Richtung Create, Read, Update and Delete (CRUD) oder Representational State Transfer (REST) tendieren. \cite{Serbout:2022:WebApiStructures}


\section{REST}
\label{chap:rest}
%vlt kurz rest allgemein beschreiben wie unten graphql + person id beispiel

Obwohl viele Web-Schnittstellen als REST-APIs bezeichnet werden, erfüllen sie selten vollständig die in Roy Fieldings Dissertation definierten REST-Prinzipien \cite{Neumann:2021:AnalysisOfRest}. 
In Wahrheit implementieren die meisten dieser Schnittstellen nur einige Aspekte von REST, ohne jedoch den vollständigen Architekturstil
\footnote{
	Eine Softwarearchitektur umfasst die strukturierten Komponenten eines Softwaresystems, die in Abhängigkeit zueinander stehen und miteinander kommunizieren müssen, um eine funktionierende Anwendung zu ermöglichen \cite{Fielding:2000:REST}. 
	Der Architekturstil legt fest, welche architektonischen Voraussetzungen erfüllt sein müssen, damit ein System diesem Stil zugeordnet werden kann.
}
zu erreichen, den Fielding beschrieben hat \cite{Neumann:2021:AnalysisOfRest}.

Das REST-Paradigma definiert sechs spezifische Einschränkungen, wovon fünf eingehalten werden müssen, um als RESTful zu gelten. 
Diese Prinzipien sind entscheidend, um die Vorteile von REST, wie Skalierbarkeit, Zustandslosigkeit und die Fähigkeit, unabhängige Dienste zu nutzen, vollständig auszuschöpfen. 
Leider zeigt die Praxis, dass viele als REST deklarierte Schnittstellen diesen Anforderungen nicht gerecht werden, was oft zu Missverständnissen und ineffizienter Implementierung führt \cite{Neumann:2021:AnalysisOfRest}.

\subsection{Client-Server}

Die Client-Server-Abstraktion ist eine essenzielle Einschränkung im REST-Architekturstil, die die Benutzerschnittstelle (Client) von der Datenspeicherung und Geschäftslogik (Server) separiert. 
Diese Trennung fördert die Möglichkeit, dass Benutzer über verschiedene Plattformen auf Anwendungen zugreifen können, während Serverfunktionen wie Datenmanagement und Verarbeitungslogik unabhängig weiterentwickelt und skaliert werden. 
Dadurch wird nicht nur die Wartbarkeit und Anpassungsfähigkeit der Systeme erhöht, sondern auch eine Plattformunabhängigkeit gewährleistet, die eine breite Nutzerbasis anspricht. 
Diese modulare Struktur unterstützt die Skalierbarkeit, indem sie die Verteilung von Lasten und die effiziente Ressourcennutzung ohne direkte Abhängigkeiten zwischen Client und Server ermöglicht, wie Fielding in seiner Arbeit „Architectural Styles and the Design of Network-based Software Architectures“ hervorhebt. \cite{Fielding:2000:REST}.


\subsection{Zustandslos}

Diese Einschränkung bezieht sich auf die Interaktion zwischen Client und Server und ist ein fundamentales Prinzip, das vorschreibt, dass jede Anfrage des Clients an den Server alle notwendigen Informationen beinhalten muss, um diese unabhängig von vorherigen Interaktionen zu verarbeiten. 
Dieses Prinzip stellt sicher, dass der Server keine Zustandsinformationen speichern muss, wodurch die Abhängigkeit von einer Anfrage zur nächsten eliminiert wird.
Aus architektonischer Sicht bietet die Zustandslosigkeit signifikante Vorteile bezüglich Visibilität, Zuverlässigkeit und Skalierbarkeit.
Doch die Performanz kann darunter leider, da es zu mehrfachen Senden gleicher Informationen kommen kann. \cite{Fielding:2000:REST}


\subsection{Cache}

Der Cache-Constraint gibt vor, dass Antworten des Servers als cacheable oder non-cacheable gekennzeichnet werden. 
Dies ermöglicht es dem Client, Antworten für zukünftige Anfragen wiederzuverwenden, was potenziell zu erheblichen Leistungssteigerungen führen kann. Allerdings kann dies die Zuverlässigkeit beeinträchtigen, da die im Cache gespeicherten Daten möglicherweise nicht mehr mit den aktuellen Daten auf dem Server übereinstimmen. \cite{Fielding:2000:REST}


\subsection{Uniform Interface}

Die Haupteigenschaft vom REST-Architekturstil ist das Uniform Interface und wird durch vier untergeordnete Einschränkungen definiert, die gemeinsam das Konzept von Ressourcen und deren Repräsentationen prägen.

\textbf{{ Ressourcen und Repräsentationen}} 

Roy Fielding definiert eine Ressource als eine benennbare Information, die über eine zeitlich variable Funktion identifiziert wird. 
Repräsentationen beschreibt Fielding als eine Byte-Sequenz, ergänzt durch Metadaten, die diese Bytes beschreiben. Die Repräsentation ist das, was als Antwort auf eine Ressourcenanforderung übermittelt wird.
Diese entscheidende Trennung von Ressource und Repräsentation erleichtert die Verwaltung von Ressourcen, indem sie es ermöglicht, dass diese unabhängig von ihren spezifischen Repräsentationen identifiziert und manipuliert werden können \cite{Fielding:2000:REST}.


\textbf{{ Identifikation und Manipulation von Ressourcen}} 

Die REST-Architektur nutzt Uniform Resource Identifiers (URIs), um Ressourcen zu identifizieren. URIs vereinen die Funktionen von URLs (zur Lokalisierung) und URNs (zur Benennung), wodurch die Flexibilität im Umgang mit Ressourcen erhöht wird, da sie eine klare und eindeutige Identifikation ermöglichen. 
Die Identifikation durch URIs sollte sich nie auf spezifische Repräsentationen beziehen, sondern auf die konzeptuelle Einordnung der Ressource.
Also eine URI soll keine Dateiendung wie \grqq path/file.json\grqq{} enthalten, um flexibel zu bleiben.
Die Manipulation von Ressourcen erfolgt über ihre Repräsentationen, wobei die Ressource selbst unverändert bleibt. 
Dies unterstützt die Skalierbarkeit und Wartung von Webanwendungen, indem es Änderungen erleichtert, ohne dass bestehende Verweise angepasst werden müssen. \cite{Fielding:2000:REST}


\textbf{{ Selbstbeschreibende Nachrichten und HATEOAS}}

Selbstbeschreibende Nachrichten gewährleisten, dass jede Anfrage oder Antwort so wenig Kontext wie möglich benötigt. 
Durch die Verwendung standardisierter Methoden und explizite Angaben zur Cacheability in den Antworten fördert dies die Zustandslosigkeit von REST-Services.

Die Einschränkung Hypermedia as the Engine of Application State (HATEOAS) zielt darauf ab, eine maximale Entkopplung zwischen Client und Server zu gewährleisten. 
Sie erfordert, dass der Client keine Kenntnisse über die interne Struktur des Services benötigt, da alle Zustandsübergänge auf dem Server durch die Auswahl von durch den Server bereitgestellten Hyperlinks gesteuert werden. 
Dies ermöglicht eine dynamische Navigation und Interaktion mit dem Service, was die Flexibilität und Erweiterbarkeit des Webservices erhöht. \cite{Fielding:2000:REST}


\subsection{Layered System}

Das Konzept des geschichteten Systems (Layered System)ermöglicht eine hierarchische Schichtenarchitektur. 
Jede Komponente der REST Architektur interagiert nur mit der direkt angrenzenden Schicht, was die Komplexität des Systems reduziert und die Unabhängigkeit von der zugrunde liegenden Plattform erhöht. 
Geschichtete Systeme können auch zur Kapselung alter Dienste und zum Schutz neuer Dienste vor veralteten Clients genutzt werden und unterstützen die Skalierbarkeit durch Lastverteilung über mehrere Netzwerke.

Durch den zusätzlich entstehenden Overhead
\footnote{
	Als Overhead bezeichnet man jene Daten, die neben den eigentlichen Nutzdaten zusätzlich übertragen oder gespeichert werden, um die Kommunikation und Datenverarbeitung zu unterstützen.
}
und die dadurch verursachte Latenz, kann die Leistung beeinträchtigt werden.
Insgesamt fördert die Kombination aus geschichtetem System und uniformen Schnittstellen die Modularität und Wartbarkeit der Architektur, indem sie ein flexibles und effizientes Management von Diensten ermöglicht. \cite{Fielding:2000:REST}


\subsection{Code-On-Demand}

Code-On-Demand ist eine optionale Einschränkung innerhalb des REST Architekturstils. 
Dieses Prinzip erweitert die Flexibilität einer Client-Server-Interaktion, indem es Servern ermöglicht, ausführbaren Code an Clients zu senden, die diesen Code dann ausführen können. 
Somit könne Server nicht nur reine Daten, sondern auch Funktionalität in Form von ausführbaren Code, an den Client zurück senden. \cite{Fielding:2000:REST}


\subsection{Zusammenfassung der REST-Constraints}

Nur wenn all diese Constraints, abgesehen von Code-On-Demand, eingehalten werden, kann ein System als RESTful deklariert werden. 
In der folgenden Auflistung werden die einzelnen Einschränkungen noch einmal zur Übersicht aufgelistet und kurz beschrieben.

\begin{enumerate}
	\item \textbf{Client-Server}:   \\  Strikte Trennung von Client und Server Anliegen
	\item \textbf{Stateless}:       \\  Jede Client-Anfrage beinhaltet alle notwendigen Informationen
	\item \textbf{Cache}:           \\  Alle Server-Antworten mit (non-)cacheable deklarieren
	
	\item \textbf{Uniform Interface} 
	\begin{enumerate}[label*=\arabic*.]
		\item \textbf{Identification of Resources}: 					  \\ Jede Ressource hat einen eindeutigen Identifikator (URI)
		\item \textbf{Manipulation of Resources through Representations}: \\ Veränderungen ausschließlich über Repräsentationen
		\item \textbf{Self-descriptive Messages}: 						  \\ Jede Nachricht kann für sich selbst stehen
		\item \textbf{HATEOAS}: 										  \\ Dynamische Client-Interaktionen durch Hyperlinks in Serverantworten
	\end{enumerate}
	
	\item \textbf{Layered System}:  \\ Geschichtete und voneinander isolierte Architektur
	\item \textbf{Code-On-Demand}:  \\ Server können ausführbaren Code an Client senden
\end{enumerate}


\section{GraphQL}

Graph Query Language (GraphQL) ist eine Datenabfrage- und Datenmanipulation-Sprache für Application Programming Interfaces. 
Kern von GraphQL ist das Typensystem, das es ermöglicht, präzise die Struktur und die benötigten Daten zu definieren. Dies ermöglicht es mit einzelnen Abfragen Operationen in sehr verschachtelten Daten durchzuführen.
Eine weiteres Merkmal von GraphQL ist die Introspektionsfähigkeit, welche eine Selbstbeschreibung des Schemas ermöglicht.
Dies unterstützt die Entwicklung und Validierung von Client-Anfragen.


\subsection{Anwendungsbeispiel}

Im folgenden Abschnitt wird anhand eines praktischen Beispiels verdeutlicht, wie ein GraphQL  \hyperref[alg:graphql-schema]{Schema} strukturiert ist, wie eine \hyperref[alg:graphql-request]{Anfrage} formuliert wird und welche Art von \hyperref[alg:graphql-response]{Antwort} vom Server zurückgegeben wird. 
Konkret betrachten wir eine Webanwendung, die drei verschiedene Datentypen umfasst: Benutzer:innen, Postings und Kommentare. 
Diese Daten sind in unterschiedlichen Datenbanken gespeichert. 
Zentral für unsere Betrachtung ist eine spezifische GraphQL-Query, die als Eingabeparameter eine ID erhält und daraufhin eine:n Benutzer:in (User) aus der Datenbank retourniert.

\begin{lstlisting}[
	language=GraphQL, 
	caption={GraphQL-Schema}, 
	label={alg:graphql-schema}
	]
	type User {
		id: Int!
		email: String
		name: String
		posts: [Post]
	}
	
	type Post {
		id: Int!
		text: String
		date: String
		author: User
		comments: [Comment]
	}
	
	type Comment {
		id: Int!
		text: String
		date: String
		commentedPost: Post
		author: User
	}
	
	type Query {
		user(id: Int!): User
	}
\end{lstlisting}

Um in dieser GraphQL-Anwendung alle Postings und Kommentare einer Person mit der ID 42 abzurufen, kann dies effizient mit einer einzigen Anfrage erfolgen. 
Dabei ist es lediglich notwendig, die erwarteten Schlüssel der JSON-Struktur entsprechend zu verschachteln.

\newpage
%\renewcommand{\lstlistingname}{Query}
\begin{lstlisting}[
	language=GraphQL, 
	caption={GraphQL-Anfrage}, 
	label={alg:graphql-request}
	]
	user(id: 42) {
		name
		email
		posts {
			text
			comments {
				text
				date
			}
		}
	}
\end{lstlisting}

Die entsprechende Server-Antwort auf die Anfrage sieht wie folgt aus:

\begin{lstlisting}[
	language=GraphQL, 
	caption={GraphQL-Antwort}, 
	label={alg:graphql-response}
	]
	"user" {
		"name": "Zaphod",
		"email": "zaphod@mail.univer.se",
		"posts": [
		{
			"text": "Answer is...",
			"comments": [
			{
				"text": "...42"
				"date": "2000-01-02"
			}
			]
		}
		]
	}
\end{lstlisting}

Betrachtet man die JSON-Antwort als Key-Value Paare, kann man erkennen, dass die Anfragen den Antworten entsprechen, nur ohne dem Value Part.


\section{Vergleich zwischen GraphQL und REST}

Der Großteil aller Web-Schnittstellen verwendet den REST-Architekturstil, auch wie bereits oben erläutert, nur ein geringer Anteil tatsächlich alle REST-Einschränkungen umsetzt.
Der zweite große und immer mehr Anteil gewinnende Player ist GraphQL.
Im Vergleich zwischen GraphQL und REST ergeben sich mehrere signifikante Unterschiede, die insbesondere in den Bereichen Performance, Flexibilität der Abfragen, Benutzerfreundlichkeit und Wartbarkeit deutlich werden. 
Diese Differenzen machen sich vor allem bei komplexen Datenanforderungen bemerkbar.
In diesem Abschnitt werden die zwei Technologien miteinander verglichen und erwogen, welche der beiden die bessere Lösung für die benötigte Schnittstelle ist.


\subsection{Effizienz}

Generell sind REST und GraphQL bei POST- und PUT-Abfragen performant ausgeglichen, jedoch zeigen sich bei GET-Abfragen signifikante Unterschiede \cite{Vohra:2022:GraphVsRestImplementation}.
Es zeigt sich, dass GraphQL eine überlegene Performance bei komplexen Abfragen aufweist.
Bei Abfragen mit vier Endpunkten und 1000 Key-Value Paaren ist die Antwort von GraphQL bereits 16-mal schneller und bei mehr als fünf Endpunkten bis zu 180-mal schneller \cite{Quinamera:2023:GraphMappingStudy}.
Eine Schwäche von REST ist das Over-
\footnote{
	Overfetching: Server retourniert mehr Daten als Client benötigt.
}
und Underfetching
\footnote{
	Underfetching: Server antwortet mit zu wenig Daten, weshalb mehrere Endpunkte angesteuert werden müssen.
}
, welches GraphQL effektiv adressiert, indem es dem Client erlaubt, in nur einer Query genau zu spezifizieren, welche Daten benötigt werden \cite{Brito:2019:MigratingToGraphQL}. 
Dies führt zu einer Reduktion der Antwortgrößen um bis zu 90 \% und somit zu der oben angeführten Steigerung der Performance \cite{Brito:2019:MigratingToGraphQL}.

Wird jedoch das Multiplexing-Feature von HTTP/2 angewendet, können mehrere Anfragen oder Methoden gleichzeitig an jedem Endpunkt ausgeführt werden, was wiederum zu besseren Antwortzeiten für REST führt.
So kann REST bei Tests, die auf Geschwindigkeit und Durchsatz ausgerichtet sind und Multiplexing verwenden, mit einer bis zu 50 \% schnelleren Antwortzeit aufzeigen. \cite{Lawi:2021:GraphVsRestPerformance}

Auch wenn die Abfragen weniger komplex sind, weist REST eine geringere Antwortzeit auf. 
Dies betrifft abfragen, wo nur ein oder zwei Endpunkte angesteuert werden und somit der GraphQL Overhead nicht ausgeglichen wird. \cite{Quinamera:2023:GraphMappingStudy}

Um das oben angeführte Beispiel für eine \hyperref[alg:graphql-request]{GraphQL-Anfrage} auch in REST darzustellen, bräuchte es mehrere Anfragen. Im ersten Schritt wird der User mit ID 42 angefragt, dann die Postings von User 42 und zuletzt die Kommentare von jedem dieser Postings.

\begin{lstlisting}[
	language=REST, 
	caption={REST-Anfragen}, 
	label={alg:rest-request}
	]
	GET /users/42
	GET /users/42/posts
	GET /posts/{post_id}/comments
\end{lstlisting}


\subsection{Bedienbarkeit}

GraphQL bietet aufgrund seiner strengen Typisierung signifikante Vorteile, da bereits vor der Ausführung einer Abfrage genaue Typüberprüfungen stattfinden, die zur Reduzierung von Laufzeitfehlern beitragen \cite{Brito:2019:MigratingToGraphQL}. 
Auf der anderen Seite erhöht jedoch die Komplexität der Anfragen die Anforderungen an das Verständnis der Datenstruktur durch die Benutzenden. 
Obwohl GraphQL es ermöglicht, komplexe Datenabfragen in einzelnen Queries durchzuführen, setzt dies voraus, dass die Nutzenden die Datenstruktur vollständig verstehen. 
Daher kann die Einarbeitungszeit für neue User höher sein und die Fehleranfälligkeit zunehmen, im Vergleich zu einer gut strukturierten und übersichtlichen REST-Schnittstelle. \cite{Quinamera:2023:GraphMappingStudy}


\subsection{Cache}

Caching-Strategien spielen eine entscheidende Rolle bei der Leistungsfähigkeit von Webanwendungen. 
REST und GraphQL verfolgen jedoch unterschiedliche Herangehensweisen. 
REST nutzt bereits vorhandene HTTP-Caching-Mechanismen, da es auf einheitlichen HTTP-Methoden aufgebaut ist. 
Auf diese Weise lassen sich Antworten auf GET-Anfragen problemlos in Standard-HTTP-Caches speichern \cite{Li:2016:RestCache}. 
Dies führt zu einer Verringerung der Serverlast und einer Verbesserung der Antwortzeiten durch die Zwischenspeicherung und Wiederverwendung von oft angeforderten Daten. 
GraphQL hingegen ist nicht standardmäßig mit HTTP-Caching ausgestattet.
Aufgrund der enormen Anpassungsfähigkeit jeder GraphQL-Anfrage sind die Anforderungen häufig individuell und entsprechen somit keiner effizienten herkömmlichen Caching-Strategie \cite{Brito:2019:MigratingToGraphQL}.
Die Implementierung spezieller Caching-Strategien für GraphQL kann es schwierig machen, die API zu entwickeln und zu warten \cite{Ala:2022:GraphVsRestCaching}.


\subsection{Zusammenfassung}

REST und GraphQL zeigen im direkten Vergleich, dass beide Technologien ihre spezifischen Stärken und Schwächen in Bezug auf Effizienz, Flexibilität, Benutzerfreundlichkeit und Caching haben. 
In Bereich der Performance hat GraphQL bei komplexeren Abfragen in den oben referenzierten Studien besser abgeschlossen, dafür kann es sich als sehr kompliziert erweisen, eine sinnvolle Caching-Strategie für GraphQL zu implementieren, was hingegen bei REST mittels HTTP-Caching ersichtlich simpler funktioniert. 
Die strenge Typisierung bei GraphQL verspricht zwar eine Reduzierung von Laufzeitfehler, doch setzt es auch ein tieferes Verständnis für die Datenstruktur voraus.

Im Hinblick auf die Entwicklung der geplanten Schnittstelle erweist sich der Architekturstil REST als die überlegene Wahl. 
Dieser Ansatz ermöglicht es den Nutzern, die Schnittstelle mit weniger spezifischem Wissen über die Datenstruktur effektiv zu nutzen, was die Einarbeitungszeit erheblich reduziert. 
Zudem erfordert das Caching keine zusätzliche Implementierung, da REST von den eingebauten HTTP-Caching-Mechanismen profitiert. 
Auch die Wartung einer REST-Schnittstelle gestaltet sich in der Regel weniger aufwendig als die einer GraphQL-basierten API, was langfristige Vorteile in Bezug auf Betriebskosten und Ressourceneinsatz bietet.

\todo{vlt noch laravel beschreiben}




%\begin{table}[h]
%	\centering
%	
%	\begin{tabular}{ll|l}
	%		
	%		1   & Client-Server       & Strikte Trennung von Client und Server Anliegen \\
	%		\hline
	%		2   & Zustandslos         & Jede Client-Anfrage beinhaltet alle notwendigen Informationen \\
	%		\hline 
	%		3   & Cache      		  & Alle Server-Antworten mit (non-)cacheable deklarieren \\
	%		\hline
	%		4   & Uniform Interface \\
	%		4.1 & Ressources          & some text \\
	%		4.2 & Representations     & some text \\
	%		4.3 & Selbstbeschreibend  & some text \\
	%		4.4 & HATEOAS             & some text \\
	%		\hline
	%		5   & Layered System      & some text \\
	%		\hline
	%		6   & Code-On-Demand      & some text \\
	%		
	%	\end{tabular}
%	
%	\caption{REST-Constraints}
%	\label{tab:REST-Constraints}
%\end{table}









\chapter{Entwurf der Schnittstelle}

In den vorangegangenen Kapiteln wurde eine detaillierte Anforderungsanalyse sowie eine gründliche Evaluierung des aktuellen Stands der Technik im Bereich der Web-Schnittstellen vorgenommen. 
Auf Grundlage dieser Analysen fiel die Entscheidung, die zu entwickelnde Web-Schnittstelle als RESTful-API zu realisieren.
In diesem Kapitel wird das Design und die Architektur der Schnittstelle definiert. 
Dabei werden die spezifischen Anforderungen und die im Rahmen der Technologiebewertung identifizierten besten Praktiken berücksichtigt, um eine effiziente, benutzerfreundliche und skalierbare Lösung zu gewährleisten.


\section{API}

Die Entwicklung der Schnittstelle erfolgt unter Einhaltung der RESTful-Prinzipien. 
Dabei werden bestimmte vorgegebene Einschränkungen beachtet. 
Zusätzlich erfolgt eine gezielte Auswahl aus verschiedenen bewährten Methoden, um die Effektivität und Konformität der Schnittstelle zu optimieren.


\subsection{RESTful}

Wie bereits in Kapitel \ref{chap:rest} erläutert, müssen fünf zentrale REST-Constraints erfüllt sein, um den von Roy Fielding definierten Anforderungen gerecht zu werden. 
Erstens ist eine deutliche Trennung zwischen Client- und Serverlogik erforderlich, wobei alle Interaktionen zustandslos sein müssen, das heißt, jede Client-Anfrage und jede Server-Antwort sollte unabhängig voneinander sein. Zweitens muss die Schnittstelle Cache-fähig sein, um effiziente Datenabrufe zu ermöglichen. 
Weiterhin müssen alle Anfragen und Fehlermeldungen den standardisierten Methoden wie PUT, GET, POST etc. folgen und einheitliche Fehlercodes wie 2xx, 3xx etc. verwenden. 
Abschließend muss die Schnittstelle den Anforderungen an ein Uniform Interface genügen, das die eindeutige Nutzung von URIs zur Identifikation und Repräsentation der Daten festlegt.


\subsection{Authentifizierung}
\todo{not sure yet... vlt das was da philipp bereits verwendet übernehmen}
Der Authentifizierungsprozess der Schnittstelle wird durch das Paket Sanctum
\footnote{
	\url{https://laravel.com/docs/11.x/sanctum} (zuletzt besucht am 24.04.2024)
} 
von Laravel gehandhabt. 
Sanctum bietet eine einfache und effektive Methode zur Authentifizierung von Web- und API-Anwendungen.
Sanctum ist ein leichtgewichtiges Authentifizierungssystem für Laravel, das speziell für die Sicherung von APIs und Single-Page-Anwendungen (SPAs) entwickelt wurde. 
Es ermöglicht eine nahtlose Authentifizierung mittels API-Token und unterstützt zusätzlich die Einbindung von Laravel's eingebautem Cookie-basierten Sitzungsauthentifizierungssystem. 
Das Tool stellt sicher, dass die Authentifizierung von Nutzern sicher und ohne unnötige Komplexität erfolgt, was es zu einem idealen Werkzeug für moderne Web-Anwendungen macht. \cite{Laravel:2023:Spec}











\chapter{Implementierung}
\todo{Enter your text here.}

\section{Prototypische Implementierung der Schnittstelle}



\chapter{Validierung der Lösung}
\todo{Enter your text here.}

\section{Vergleich mit ähnlichen Systemen}

\section{Experteninterviews - Durchführung}

\section{Experteninterviews - Analyse}



\chapter{Ergebnisse}
\todo{Enter your text here.}

\section{Ausblick}

\section{Zusammenfassung}


% Remove following line for the final thesis.
\input{intro.tex} % A short introduction to LaTeX.

\backmatter

% Use an optional list of figures.
\listoffigures % Starred version, i.e., \listoffigures*, removes the toc entry.

% Use an optional list of tables.
\cleardoublepage % Start list of tables on the next empty right hand page.
\listoftables % Starred version, i.e., \listoftables*, removes the toc entry.

% Use an optional list of alogrithms.
\listofalgorithms
\addcontentsline{toc}{chapter}{Liste der Algorithmen}

% Add an index.
\printindex

% Add a glossary.
\printglossaries

% Add a bibliography.
\bibliographystyle{IEEEtran}
\bibliography{thesis}

\end{document}
